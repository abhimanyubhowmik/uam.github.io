<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Uncertainity aware mapping in underwater robots">
  <meta name="keywords" content="Nerfies, D-NeRF, NeRF">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Uncertainity aware mapping in underwater robots</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/mir_logo.jpeg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://abhimanyubhowmik.github.io/">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://github.com/abhimanyubhowmik/Underwater_Depth_Estimation">
            DepthDive
          </a>
          <a class="navbar-item" href="https://ntnu-arl.github.io/refractive-camera-model-in-vio/">
            ReAqROVIO
          </a>
        </div>
      </div>
    </div>

  </div>
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Uncertainty Aware Mapping for Vision-Based Underwater Robots</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://abhimanyubhowmik.github.io/">Abhimanyu Bhowmik</a><sup>1,2</sup>,</span>
            <span class="author-block">
              <a href="https://www.ntnu.no/ansatte/mohit.singh">Mohit Singh</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://www.ntnu.no/ansatte/martin.ludvigsen">Martin Ludvigsen</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://www.ntnu.edu/employees/konstantinos.alexis">Kostas Alexis</a><sup>1</sup>,
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Norwegian University of Science and Technology,</span>
            <span class="author-block"><sup>2</sup>Université de Toulon</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://studntnu-my.sharepoint.com/:b:/g/personal/abhimanb_ntnu_no/EV3ML4ytNghLiCYTdz5NNT0B_IXGyJxZ9UnlYyFtiOtAgg?e=7vEteq"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Poster</span>
                </a>
              </span>
              <!-- <span class="link-block">
                <a href="https://arxiv.org/abs/2011.12948"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span> -->
              <!-- Video Link. -->
              <!-- <span class="link-block">
                <a href="https://www.youtube.com/watch?v=MrKrnHhk8IA"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span> -->
              <!-- Code Link. -->
              <span class="link-block">
                <a href="#"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code Comming Soon</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
              <span class="link-block">
                <a href="https://huggingface.co/datasets/ntnu-arl/underwater-datasets"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Dataset</span>
                  </a>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video id="teaser" autoplay muted loop playsinline height="100%">
        <source src="./static/videos/Thesis_Teaser.mp4"
                type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        <span class="dnerf"></span> The Overall Framework : Uncertainity Aware Mapping and Planning in Simulation using GBPlanner
      </h2>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Vision-based underwater robots can be useful in inspecting and exploring confined spaces where traditional sensors and preplanned paths cannot be followed. Sensor noise and situational change can cause significant uncertainty in environmental representation. Thus, this paper explores how to represent mapping inconsistency in vision-based sensing and incorporate depth estimation confidence into the mapping framework. The scene depth and the confidence are estimated using the RAFT-Stereo model and are integrated into a voxel-based mapping framework, Voxblox. Improvements in the existing Voxblox weight calculation and update mechanism are also proposed. Finally, a qualitative analysis of the proposed method is performed in a confined pool and in a pier in the Trondheim fjord. Experiments using an underwater robot demonstrated the change in uncertainty in the visualization. 
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
</section>


<section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered">

      <!-- Visual Effects. -->
      <div class="column">
        <div class="content">
          <h2 class="title is-3">Indoor Lab Environment</h2>
          <p>
            Indoor experiments were conducted at NTNU's MC-lab in a 40 m × 6.45 m × 1.5 m water tank. A custom BlueROV2 Heavy with stereo camera and IMU was manually piloted along varied trajectories, covering over half the tank while collecting synchronized data.
          </p>
          <video id="dollyzoom" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/Thesis Video_1_new.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>
      <!--/ Visual Effects. -->

      <!-- Matting. -->
      <div class="column">
        <h2 class="title is-3">Field Experiment</h2>
        <div class="columns is-centered">
          <div class="column content">
            <p>
              The field experiments were conducted at a pier in the Trondheim Fjord, at a depth of approximately 7 meters. During the trials, the robot descended to a depth of about 0.7 meters and traveled a distance of 20 to 25 meters over a period of 12 minutes.
            </p>
            <video id="matting-video" controls playsinline height="100%">
              <source src="./static/videos/Thesis Video_2_new_2.mp4"
                      type="video/mp4">
            </video>
          </div>

        </div>
      </div>
    </div>
    <!--/ Matting. -->

    <!-- Animation. -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Exploration</h2>

        <!-- Re-rendering. -->
        <h3 class="title is-4">HoloOcean Simulation</h3>
        <div class="content has-text-justified">
          <p>A modified HoloOcean simulator was used to explore the OpenWater environment, with the HoveringAUV agent controlled via a PID controller for position, velocity, and attitude tracking across 4 DOFs. Confidence was emulated instead of using RAFT-Stereo to enable faster processing in simulation. Our modified Voxblox was used for visualization voxel confidence and, confidence density was computed as total confidence divided by surface area within a volume.
          </p>
        </div>
        <div class="content has-text-centered">
          <video id="replay-video"
                 controls
                 muted
                 preload
                 playsinline
                 width="75%">
            <source src="./static/videos/Thesis Video_3_final.mp4"
                    type="video/mp4">
          </video>
        </div>
        <!--/ Re-rendering. -->

      </div>
    </div>
    <!--/ Animation. -->


    <!-- Concurrent Work. -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Related Links</h2>

        <div class="content has-text-justified">
          <p>
            Here are the key libraries and frameworks used in this project.
          </p>
          <p>
            <a href="https://github.com/ethz-asl/voxblox">Voxblox</a> a volumetric mapping library based mainly on Truncated Signed Distance Fields (TSDFs).
          </p>
          <p>
            <a href="https://github.com/princeton-vl/RAFT-Stereo">RAFT-Stereo</a> a deep architecture for rectified stereo based on the optical flow network  <a href="https://github.com/princeton-vl/RAFT">RAFT</a>.
          </p>
          <p>
            <a href="https://github.com/ntnu-arl/reaqrovio">ReAqROVIO</a> is a modified implementation of <a href="https://github.com/ethz-asl/rovio">ROVIO</a>, which enables Visual-Inertial Odometry (VIO) underwater without the need of camera calibration in the water.
          </p>
          <p>
             <a href="https://github.com/ntnu-arl/gbplanner_ros">GBPlanner2</a>, is a Graph-based Exploration Planner for Subterranean Environments.
          </p>
        </div>
      </div>
    </div>
    <!--/ Concurrent Work. -->

   <!--/ Acknowledgement section -->
    <div class="columns is-centered">
  <div class="column is-full-width">
    <h2 class="title is-3">Acknowledgements</h2>

    <div class="content has-text-justified">
      <p>
        This work was conducted as part of the Erasmus Mundus Joint Master Degree in Marine and Maritime Intelligent Robotics (EMJMD MIR). The first author received funding from the European Union under the Erasmus+ Programme.
      </p>

      <!-- Single Merged Logo Image -->
      <div class="has-text-centered">
        <figure class="image is-inline-block">
          <img src="static/images/MIR Poster Logo.png" alt="Acknowledgement Logos">
        </figure>
      </div>
    </div>
  </div>
</div>

<!--/ Acknowledgements Section -->


  </div>
</section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{unpublished,
  author    = {Bhowmik, Abhimanyu and Singh, Mohit and Sannigrahi, Madhushree and Ludvigsen, Martin and Alexis, Kostas},
  title     = {Uncertainty Aware Mapping for Vision-Based Underwater Robots},
  workshop   = {Field Robotics at ICRA},
  year      = {2025},
}</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="https://studntnu-my.sharepoint.com/:b:/g/personal/abhimanb_ntnu_no/EV3ML4ytNghLiCYTdz5NNT0B_IXGyJxZ9UnlYyFtiOtAgg?e=7vEteq">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/abhimanyubhowmik" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            The website template is borrowed from <a href="https://github.com/nerfies/nerfies.github.io"> Nerfies</a> and it is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
